7/16 5:06妈的失眠了
title.principals.tsv.gz数据集貌似是可以使用的。如果扩展需要可以使用评分信息title.ratings.tsv.gz
imdb现在下载貌似必须注册aws，没有境外信用卡呀 淘宝买了一个但是卖家不发货 暂时找到一个镜像 ftp://ftp.funet.fi/pub/mirrors/ftp.imdb.com/pub/temporaryaccess/
注意gedit不能解决但是sublime没有问题的编码问题
使用trim.py脚本trim数据，每一行是一个演员。然后使用Proprocess进一步处理，每个演员出演电影使用"|"隔开，注意是含有空格的
建立电影到演员的倒排表之后，共有701579个电影，进一步的，如果一个电影只有一个演员出演，那么可以直接去掉这部电影,处理之后共510396个电影。同样的，如果演员参演电影为0可以直接去掉，去掉之后共96w左右电影。如果对倒排表再进行一次倒排，则可以去掉所有死链接的节点，以后考虑做。
计算了图的规模，predata表中电影数量/演员数量：4514592/1131471=3.9900200712170264,即每个演员的子节点有4个。
inverted表中演员数量/电影数量:4323409/510396=8.470695303254727，即每个电影的子节点有8.5个。
那么大概推算：每个演员的共同出演电影演员数量的3*8=24约为20。6度总规模是20^6-1=6400w演员数据，64M条演员数据。不过共同数量应该小于20.
根据宽搜需要的数据，整理如下：

map接受(数据源：数据)
alldata:	<name,children>
cachedata:	<name,children,distance,status,parent>

map发送(数据源 <key,value>)
alldata.sourcedata	组装成一条open数据，当做cachedata.open发送
alldata.other		<name,children>
cachedata.open		<child,name,distance,status,parent>
cachedata.all		<name,children,distance,status,parent> open状态变成close状态

reduce接受(数据源 value 操作)
self.alldata	children									可能用于组成新的cachedata
self.cachedata	children,distance,status,parent				写入已有的cachedata
parent			parent's<children,distance,status,parent>	组成新的cachedata,但会一直收到source数据，因此还需要当前状态为unknown，状态变为open