7/16 5:06妈的失眠了
title.principals.tsv.gz数据集貌似是可以使用的。如果扩展需要可以使用评分信息title.ratings.tsv.gz
imdb现在下载貌似必须注册aws，没有境外信用卡呀 淘宝买了一个但是卖家不发货 暂时找到一个镜像 ftp://ftp.funet.fi/pub/mirrors/ftp.imdb.com/pub/temporaryaccess/
注意gedit不能解决但是sublime没有问题的编码问题
使用trim.py脚本trim数据，每一行是一个演员。然后使用Proprocess进一步处理，每个演员出演电影使用"|"隔开，注意是含有空格的
建立电影到演员的倒排表之后，共有701579个电影，进一步的，如果一个电影只有一个演员出演，那么可以直接去掉这部电影,处理之后共510396个电影。同样的，如果演员参演电影为0可以直接去掉，去掉之后共96w左右演员。如果对倒排表再进行一次倒排，则可以去掉所有死链接的节点，以后考虑做。
计算了图的规模，predata表中电影数量/演员数量：4514592/1131471=3.9900200712170264,即每个演员的子节点有4个。
inverted表中演员数量/电影数量:4323409/510396=8.470695303254727，即每个电影的子节点有8.5个。
那么大概推算：每个演员的共同出演电影演员数量的3*8=24约为20。6度总规模是20^6-1=6400w演员数据，64M条演员数据。不过共同数量应该小于20.

根据宽搜需要的数据，整理如下：
map接受(数据源：数据)
alldata:	<name,children>
cachedata:	<name,children,distance,status,parent>

map发送(数据源 <key,value>)
alldata.sourcedata	组装成一条open数据，当做cachedata.open发送
alldata.all			<name,children>
cachedata.open		<child,distance,parent>open 状态变成close状态,parent加上自己
cachedata.all		<name,distance,status,parent> 

reduce接受(数据源 value 操作)
self.alldata	children						可能用于组成新的cachedata
self.cachedata	distance,status,parent			写入已有的cachedata
parent			parent's<distance,parent>		组成新的cachedata,但会一直收到source数据，因此还需要当前状态为unknown，状态变为open

其中source一直发送数据是为了启动搜索过程，source和dest使用参数进行传递。
reduce和driver之间通过参数传递信息，driver发送dest,reduce发送搜索到的路径，""表示空
但是好像reduce和map都无法接受修改config，只能考虑通过写入文件的方式传递结果


7/16 20:38
首先可以去掉status信息，cachedata中，只有opendata保存的数据是<name,children,distance,status,parent>,其余的只保存<name>
重新设计协议
map接受(数据源：数据)
alldata:			<name,children>
cachedata.open:		<name,children distance parent>
cachedata.close:	<name>
map发送(数据源 <key,value>)
alldata.sourcedata	组装成一条open数据，当做cachedata.open发送
alldata.other		<name,children>
cachedata.open		<child,distance parent> parent加上自己
cachedata.all		<name,value="<c>">（指定的一个特殊字符串，这个字符串不会再其他数据中出现）
reduce接受(数据源 value 操作)
self.alldata	children						可能用于组成新的cachedata
self.close		"<c>"							写入已有的cachedata
parent			parent's<distance parent>		组成新的cachedata,但会一直收到source数据，因此还需要当前状态为unknown，状态变为open

首先观察原输出，得到时间消耗(多次)：
12928ms;13257ms;12233ms;13243ms;14317ms;19229ms;31282ms;42274ms;29474ms;33563ms;29392ms;27507ms;
12952ms;13403ms;13278ms;12254ms;12177ms;18221ms;29260ms;42803ms;29289ms;38331ms;29564ms;29464ms;
15022ms;13463ms;11262ms;14198ms;14244ms;19286ms;29267ms;41313ms;32321ms;31518ms;28290ms;29531ms; 
最后两轮的文件大小是(多次)：
385M,387M
更新之后的输出，时间消耗:
14830ms;13277ms;13274ms;13264ms;19532ms;13247ms;12378ms;13220ms;13259ms;11163ms;17245ms;12256ms; 
15049ms;12283ms;14261ms;13317ms;18303ms;13241ms;13282ms;12241ms;13201ms;12221ms;18234ms;11295ms;
14935ms;13274ms;13246ms;12237ms;19176ms;12322ms;13250ms;11225ms;13325ms;14229ms;18213ms;12161ms; 
文件大小:69.6M


尝试通过DistribtionCacheFile读取open的数据点，但是必须保证数据点足够小。
如果数据点已经太大了没办法读取，就不再读取了，直接发送所有数据。
第11次迭代需要open数据有200000条,总的数据规模大概
如果预读open数据，重新设计协议
map接受(数据源：数据)
opendata			setup的时候读取文件，每个数据一行，全是open数据的name
alldata:			<name,children>
cachedata.open:		<name,children distance parent>
cachedata.close:	<name>
map发送(数据源 <key,value>)
// alldata.sourcedata		组装成一条open数据，当做cachedata.open发送,不能发送cachedata.all数据，必须发送自己<name,children>
alldata.sourcedata		<name,distance parent>，fake自己是被父节点open的
alldata.other&inopen	<name,children>
cachedata.open			<child,distance parent> parent加上自己
cachedata.all			<name,value="<c>">（指定的一个特殊字符串，这个字符串不会再其他数据中出现）
reduce接受(数据源 value 操作)
self.alldata	children						可能用于组成新的cachedata
self.close		"<c>"							写入已有的cachedata
parent			parent's<distance parent>		组成新的cachedata,需要当前状态不是close。需要把children写入opendata

Read 50380 lines, size: 29870;		8400ms; 
Read 715353 lines, size: 193718;	22702ms; 
Read 2551069 lines, size: 635339;	49713ms; 
depth=6的时候没有错误，但是用时较长21407ms。应该设置成5
depth=5:	7999ms;5532ms;5255ms;6251ms;7273ms; 
depth=13:	6927ms;5541ms;5306ms;5255ms;6221ms;20204ms;32283ms;39317ms;32427ms;22268ms;21252ms;22171ms;23227ms;
conf.set必须在Job.getInstance之前啊我的天!


TODO:优化输入，使输入不再那么严格
http://hadooptutorial.info/mapreduce-multiple-outputs-use-case/给出了一些运行时空间参数设置
